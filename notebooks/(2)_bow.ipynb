{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b5059eb",
   "metadata": {},
   "source": [
    "# Bag Of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1cd23d4",
   "metadata": {},
   "source": [
    "IMPORTING LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "991f08d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "from sklearn.metrics import accuracy_score , precision_score , recall_score , f1_score , roc_auc_score , confusion_matrix "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec51b218",
   "metadata": {},
   "source": [
    "* 0 -> business\n",
    "\n",
    "* 1 -> entertainment\n",
    "\n",
    "* 2 -> politics\n",
    "\n",
    "* 3 -> sport\n",
    "\n",
    "* 4 -> tech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f19fb2b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>tv future hand viewer home theatre system plas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>worldcom bos leave book alone former worldcom ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>tiger wary farrell gamble leicester say rush m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>yeading face newcastle fa cup premiership side...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>ocean twelve raid box office ocean twelve crim...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   category                                               text\n",
       "0         4  tv future hand viewer home theatre system plas...\n",
       "1         0  worldcom bos leave book alone former worldcom ...\n",
       "2         3  tiger wary farrell gamble leicester say rush m...\n",
       "3         3  yeading face newcastle fa cup premiership side...\n",
       "4         1  ocean twelve raid box office ocean twelve crim..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/sarthaksharna/Text_Classification/data/cleaned_bbc_text')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b905a75",
   "metadata": {},
   "source": [
    "TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19f6a861",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['text']\n",
    "\n",
    "y = df['category']\n",
    "\n",
    "X_train , X_test , y_train , y_test = train_test_split(X , y , test_size = 0.2 , random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d53e459",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1694,), (424,), (1694,), (424,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape , X_test.shape , y_train.shape , y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3269c400",
   "metadata": {},
   "source": [
    "TRAINING MODELS IN A PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22bd9704",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'MultinomialNB' : MultinomialNB(),\n",
    "    'LogisticRegression' : LogisticRegression(),\n",
    "    'SVC' : SVC(),\n",
    "    'RandomForestClassifier' : RandomForestClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3563295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultinomialNB \n",
      "\n",
      "Train Accuracy : 0.999409681227863\n",
      "Train Precision : 0.9993865030674847\n",
      "Train Recall : 0.9995073891625615\n",
      "Train F1-Score : 0.999446171213404\n",
      "\n",
      "\n",
      "Test Accuracy : 0.9764150943396226\n",
      "Test Precision : 0.9760236916310256\n",
      "Test Recall : 0.9772500758755054\n",
      "Test F1-Score : 0.9762445470882426 \n",
      "\n",
      "Confusion Matrix : \n",
      " [[92  0  4  0  1]\n",
      " [ 1 77  2  0  1]\n",
      " [ 1  0 77  0  0]\n",
      " [ 0  0  0 94  0]\n",
      " [ 0  0  0  0 74]]\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "LogisticRegression \n",
      "\n",
      "Train Accuracy : 1.0\n",
      "Train Precision : 1.0\n",
      "Train Recall : 1.0\n",
      "Train F1-Score : 1.0\n",
      "\n",
      "\n",
      "Test Accuracy : 0.9693396226415094\n",
      "Test Precision : 0.9693971428925761\n",
      "Test Recall : 0.9687269876273314\n",
      "Test F1-Score : 0.9689767654384388 \n",
      "\n",
      "Confusion Matrix : \n",
      " [[93  0  4  0  0]\n",
      " [ 1 79  0  1  0]\n",
      " [ 2  2 72  1  1]\n",
      " [ 0  0  0 94  0]\n",
      " [ 0  0  0  1 73]]\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "SVC \n",
      "\n",
      "Train Accuracy : 0.9988193624557261\n",
      "Train Precision : 0.9988944193061841\n",
      "Train Recall : 0.9988920045471769\n",
      "Train F1-Score : 0.9988926074870716\n",
      "\n",
      "\n",
      "Test Accuracy : 0.9551886792452831\n",
      "Test Precision : 0.9546125273327052\n",
      "Test Recall : 0.9537351818553838\n",
      "Test F1-Score : 0.9538910247715817 \n",
      "\n",
      "Confusion Matrix : \n",
      " [[93  0  3  0  1]\n",
      " [ 1 78  1  0  1]\n",
      " [ 3  2 69  3  1]\n",
      " [ 0  0  0 93  1]\n",
      " [ 0  1  0  1 72]]\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "RandomForestClassifier \n",
      "\n",
      "Train Accuracy : 1.0\n",
      "Train Precision : 1.0\n",
      "Train Recall : 1.0\n",
      "Train F1-Score : 1.0\n",
      "\n",
      "\n",
      "Test Accuracy : 0.9599056603773585\n",
      "Test Precision : 0.9645072765072765\n",
      "Test Recall : 0.9565993696577889\n",
      "Test F1-Score : 0.9596450162400041 \n",
      "\n",
      "Confusion Matrix : \n",
      " [[96  0  1  0  0]\n",
      " [ 1 77  1  2  0]\n",
      " [ 4  0 71  3  0]\n",
      " [ 0  0  0 94  0]\n",
      " [ 3  0  1  1 69]]\n",
      "\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model_name , clf in models.items() :\n",
    "    pipe = Pipeline(\n",
    "        [\n",
    "            ('bow' , CountVectorizer(ngram_range = (1,2))),\n",
    "            ('classifier' , clf)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "    pipe.fit(X_train , y_train)\n",
    "\n",
    "    y_pred_train = pipe.predict(X_train)\n",
    "    y_pred_test = pipe.predict(X_test)\n",
    "\n",
    "    print(f'{model_name} \\n')\n",
    "\n",
    "    print(f'Train Accuracy : {accuracy_score(y_train , y_pred_train)}')\n",
    "    print(f'Train Precision : {precision_score(y_train , y_pred_train , average = \"macro\")}')\n",
    "    print(f'Train Recall : {recall_score(y_train , y_pred_train , average = \"macro\")}')\n",
    "    print(f'Train F1-Score : {f1_score(y_train , y_pred_train , average = \"macro\")}')\n",
    "\n",
    "    \n",
    "    print('\\n')\n",
    "\n",
    "    print(f'Test Accuracy : {accuracy_score(y_test , y_pred_test)}')\n",
    "    print(f'Test Precision : {precision_score(y_test , y_pred_test , average = \"macro\")}')\n",
    "    print(f'Test Recall : {recall_score(y_test , y_pred_test , average = \"macro\")}')\n",
    "    print(f'Test F1-Score : {f1_score(y_test , y_pred_test , average = \"macro\")}' , '\\n')\n",
    "\n",
    "    print(f'Confusion Matrix : \\n {confusion_matrix(y_test , y_pred_test)}')\n",
    "\n",
    "    print('\\n')\n",
    "    print('=' * 50)\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f474bee",
   "metadata": {},
   "source": [
    "HYPERPARAMETER TUNING THE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6685ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelines = {\n",
    "    'SVC': Pipeline([\n",
    "        ('bow', CountVectorizer(ngram_range=(1, 2))),\n",
    "        ('classifier', SVC())\n",
    "    ]),\n",
    "\n",
    "    'LogisticRegression': Pipeline([\n",
    "        ('bow', CountVectorizer(ngram_range=(1, 2))),\n",
    "        ('classifier', LogisticRegression())\n",
    "\n",
    "    ]),\n",
    "\n",
    "    'RandomForestClassifier' : Pipeline([\n",
    "        ('bow' , CountVectorizer(ngram_range = (1,2))),\n",
    "        ('classifier' , RandomForestClassifier())\n",
    "    ])\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# HYPERPARAMETERS\n",
    "\n",
    "param_grids = {\n",
    "    'SVC': {\n",
    "        'classifier__C' :  [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'classifier__kernel' : ['linear', 'rbf']\n",
    "    },\n",
    "\n",
    "    'LogisticRegression' : {\n",
    "        'classifier__C' : [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'classifier__penalty' : ['l1' , 'l2' , 'elasticnet']\n",
    "\n",
    "    },\n",
    "\n",
    "    'RandomForestClassifier' : {\n",
    "        'classifier__n_estimators' : [100 , 150 , 200],\n",
    "        'classifier__max_depth' : [None , 10 , 20 , 30 , 40]\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Storing results \n",
    "\n",
    "results = []\n",
    "\n",
    "for name in pipelines.keys() :\n",
    "    print(f'Tuning {name} .... !! ')\n",
    "\n",
    "    randomcv = RandomizedSearchCV(\n",
    "        estimator = pipelines[name],\n",
    "        param_distributions = param_grids[name] , \n",
    "        n_iter = 10 ,\n",
    "        cv = 5 , \n",
    "        scoring = 'accuracy' ,\n",
    "        n_jobs = -1\n",
    "    )\n",
    "\n",
    "    randomcv.fit(X_train , y_train)\n",
    "\n",
    "    y_pred_tuned = randomcv.predict(X_test)\n",
    "\n",
    "    results.append(\n",
    "        {\n",
    "        'Model': name,\n",
    "        'Best Params': randomcv.best_params_,\n",
    "        'Best CV Score': randomcv.best_score_,\n",
    "        'Test Accuracy': accuracy_score(y_test, y_pred_tuned),\n",
    "        'Test Precision': precision_score(y_test, y_pred_tuned, average='weighted'),\n",
    "        'Test Recall': recall_score(y_test, y_pred_tuned, average='weighted'),\n",
    "        'Test F1 Score': f1_score(y_test, y_pred_tuned, average='weighted')\n",
    "        }\n",
    "    )\n",
    "\n",
    "    print(f\" Best params for {name}: {randomcv.best_params_}\")\n",
    "    \n",
    "    print(f\" Test Accuracy: {accuracy_score(y_test, y_pred_tuned):.4f}\")\n",
    "\n",
    "    print('\\n')\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32a0dea",
   "metadata": {},
   "source": [
    "STORING THE TUNED RESULTS IN A DATAFRAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4d3193b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Best Params</th>\n",
       "      <th>Best CV Score</th>\n",
       "      <th>Test Accuracy</th>\n",
       "      <th>Test Precision</th>\n",
       "      <th>Test Recall</th>\n",
       "      <th>Test F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>{'classifier__kernel': 'linear', 'classifier__...</td>\n",
       "      <td>0.963994</td>\n",
       "      <td>0.974057</td>\n",
       "      <td>0.973907</td>\n",
       "      <td>0.974057</td>\n",
       "      <td>0.973928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'classifier__penalty': 'l2', 'classifier__C':...</td>\n",
       "      <td>0.966942</td>\n",
       "      <td>0.974057</td>\n",
       "      <td>0.973959</td>\n",
       "      <td>0.974057</td>\n",
       "      <td>0.973994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>{'classifier__n_estimators': 150, 'classifier_...</td>\n",
       "      <td>0.945107</td>\n",
       "      <td>0.957547</td>\n",
       "      <td>0.959931</td>\n",
       "      <td>0.957547</td>\n",
       "      <td>0.957647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model                                        Best Params  \\\n",
       "0                     SVC  {'classifier__kernel': 'linear', 'classifier__...   \n",
       "1      LogisticRegression  {'classifier__penalty': 'l2', 'classifier__C':...   \n",
       "2  RandomForestClassifier  {'classifier__n_estimators': 150, 'classifier_...   \n",
       "\n",
       "   Best CV Score  Test Accuracy  Test Precision  Test Recall  Test F1 Score  \n",
       "0       0.963994       0.974057        0.973907     0.974057       0.973928  \n",
       "1       0.966942       0.974057        0.973959     0.974057       0.973994  \n",
       "2       0.945107       0.957547        0.959931     0.957547       0.957647  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395dbba4",
   "metadata": {},
   "source": [
    "THEREFORE BEST ACCURACY USING BOW :\n",
    "\n",
    "--> MULTINOMIAL NAIVE BAYES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880bd299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
